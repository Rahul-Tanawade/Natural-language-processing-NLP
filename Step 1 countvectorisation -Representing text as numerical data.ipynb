{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled7.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNnVb6tAVfOZK3Yh1XUvWOT"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgMNzD2zkCuS"
      },
      "source": [
        "**Representing text as numerical data**\n",
        "\n",
        "raw data, a sequence of symbols cannot be fed directly to the algorithms themselves as most of them expect numerical feature vectors with a fixed size\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBC6t12BlUg5"
      },
      "source": [
        "We will use CountVectorizer to \"convert text into a matrix of token counts\":\n",
        "\n",
        "4 Steps for Vectorization\n",
        "\n",
        "Import\n",
        "\n",
        "Instantiate\n",
        "\n",
        "Fit\n",
        "\n",
        "Transform"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6XpTOoujgPd"
      },
      "source": [
        "simple_train = ['call you tonight', 'Call me a cab', 'please call me.. please']"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ai5gjpJGldW8",
        "outputId": "746e7222-3623-431b-a9f1-3a7d263bce49"
      },
      "source": [
        "#step 1\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "#step 2\n",
        "cv=CountVectorizer()\n",
        "#step 3\n",
        "cv.fit(simple_train) #Alphabetical order & No duplicate words\n",
        "print(cv.get_feature_names())\n",
        "#step 4 transform training data into a 'document-term matrix'\n",
        "simple_train_dtm=cv.transform(simple_train)\n",
        "simple_train_dtm\n",
        "\n",
        "#3 rows x 6 columns\n",
        "#document = rows , Because there were 3 documents\n",
        "#term = columns , 6 terms that were learned during the fitting steps cv.get_feature_names()\n",
        "\n",
        "## convert sparse matrix to a dense matrix\n",
        "simple_train_dtm.toarray()\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['cab', 'call', 'me', 'please', 'tonight', 'you']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<3x6 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 9 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135
        },
        "id": "HsNIC7ytqQ-J",
        "outputId": "f8112616-0892-41f1-911c-82c003abe400"
      },
      "source": [
        "#examine the vocabulary and document-term matrix together\n",
        "import pandas as pd\n",
        "x=pd.DataFrame(simple_train_dtm.toarray(),columns=cv.get_feature_names())\n",
        "#We will be training our model on this (X), that's why we need this"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cab</th>\n",
              "      <th>call</th>\n",
              "      <th>me</th>\n",
              "      <th>please</th>\n",
              "      <th>tonight</th>\n",
              "      <th>you</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   cab  call  me  please  tonight  you\n",
              "0    0     1   0       0        1    1\n",
              "1    1     1   1       0        0    0\n",
              "2    0     1   1       2        0    0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2xy929H1IIi"
      },
      "source": [
        "vect.fit(train) learns the vocabulary of the training data\n",
        "\n",
        "vect.transform(train) uses the fitted vocabulary to build a document-term matrix from the training data\n",
        "\n",
        "vect.transform(test) uses the fitted vocabulary to build a document-term matrix from the testing data (and ignores tokens it hasn't seen before)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 94
        },
        "id": "AyQdM7ify95o",
        "outputId": "64584a50-9b1a-428b-e02e-fa323e8cbb25"
      },
      "source": [
        "# example text for model testing\n",
        "simple_test = ['Please don\\'t call me']\n",
        "\n",
        "#In order to make a prediction, the new observation must have the same features as the training observations, both in number and meaning.\n",
        "simple_test_dtm =cv.transform(simple_test)\n",
        "print(simple_test_dtm.toarray())\n",
        "pd.DataFrame(simple_test_dtm.toarray(), columns=cv.get_feature_names())\n",
        "\n",
        "#It dropped the word \"don't\", why are we ok with the fact that the word \"don't\" drops?\n",
        "#If we give a new word to predict the response, our model would not know what to do anyway\n",
        "#In essence, we did not train on the feature \"don't\" so our model would not be able to predict based on that new feature"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 1 1 1 0 0]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cab</th>\n",
              "      <th>call</th>\n",
              "      <th>me</th>\n",
              "      <th>please</th>\n",
              "      <th>tonight</th>\n",
              "      <th>you</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   cab  call  me  please  tonight  you\n",
              "0    0     1   1       1        0    0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HFKxrd1yp-J"
      },
      "source": [
        "A corpus of documents can thus be represented by a matrix with one row per document and one column per token (e.g. word) occurring in the corpus.\n",
        "\n",
        "We call vectorization the general process of turning a collection of text documents into numerical feature vectors. This specific strategy (tokenization, counting and normalization) is called the Bag of Words or \"Bag of n-grams\" representation. Documents are described by word occurrences while completely ignoring the relative position information of the words in the document."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kqmvv3Y3yryA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}